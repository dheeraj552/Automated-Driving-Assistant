// 

import os import pathlib
if "models" in pathlib.Path.cwd().parts: while "models" in pathlib.Path.cwd().parts:
os.chdir('..')
elif not pathlib.Path('models').exists():
!git clone --depth 1 https://github.com/tensorflow/models
import numpy as np import os
import six.moves.urllib as urllib import sys
import tarfile
import tensorflow as tf import zipfile
import urllib.request
from collections import defaultdict from io import StringIO
from matplotlib import pyplot as plt from PIL import Image
from IPython.display import display import cv2
from tensorflow.keras.preprocessing.image import ImageDataGenerator from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.layers import AveragePooling2D from tensorflow.keras.layers import Dropout
from tensorflow.keras.layers import Flatten from tensorflow.keras.layers import Dense from tensorflow.keras.layers import Input from tensorflow.keras.models import Model from tensorflow.keras.optimizers import Adam
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input from tensorflow.keras.preprocessing.image import img_to_array
from tensorflow.keras.preprocessing.image import load_img from tensorflow.keras.utils import to_categorical
11
from sklearn.preprocessing import LabelBinarizer from sklearn.model_selection import train_test_split from sklearn.metrics import classification_report from imutils import paths
import matplotlib.pyplot as plt import numpy as np
import argparse import os
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input from tensorflow.keras.preprocessing.image import img_to_array
from tensorflow.keras.models import load_model from imutils.video import VideoStream
import numpy as np
import argparse
import imutils
import time
!pip install tensorflow-object-detection-api
from object_detection.utils import ops as utils_ops
from object_detection.utils import label_map_util
from object_detection.utils import visualization_utils as vis_util
# patch tf1 into `utils.ops`
utils_ops.tf = tf.compat.v1
# Patch the location of gfile
tf.gfile = tf.io.gfile
def load_model1(model_name):
base_url = 'http://download.tensorflow.org/models/object_detection/' model_file = model_name + '.tar.gz'
model_dir = tf.keras.utils.get_file( fname=model_name,
origin=base_url + model_file, untar=True)
model_dir = pathlib.Path(model_dir)/"saved_model" model = tf.saved_model.load(str(model_dir))
model = model.signatures['serving_default'] return model
# List of the strings that is used to add correct label for each box. PATH_TO_LABELS = 'models/research/object_detection/data/mscoco_label
map.pbtxt'
category_index = label_map_util.create_category_index_from_labelmap( PATH_TO_LABELS, use_display_name=True)
12
#Loading ssid_mobilenet model
model_name = 'ssd_mobilenet_v1_coco_2018_01_28'
detection_model = load_model1(model_name)
def run_inference_for_single_image(model, image):
image = np.asarray(image)
input_tensor = tf.convert_to_tensor(image)
input_tensor = input_tensor[tf.newaxis,...]
output_dict = model(input_tensor)
num_detections = int(output_dict.pop('num_detections'))
output_dict = {key:value[0, :num_detections].
numpy()
for key,value in output_dict.items()}
output_dict['num_detections'] = num_detections
output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)
if 'detection_masks' in output_dict:
detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks( output_dict['detection_masks'], output_dict['detection_boxes'], image.shape[0], image.shape[1])
detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,
tf.uint8)
output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()
return output_dict
path = "/content/a1.jpg"
image_np = cv2.imread(path)
image_np = cv2.cvtColor(image_np,cv2.COLOR_BGR2RGB) cv2.imshow("win",image_np)
img = plt.imread(path) plt.imshow(img)
path = "/content/a1.jpg"
image_np = cv2.imread(path)
image_np = cv2.cvtColor(image_np,cv2.COLOR_BGR2RGB)
output_dict = run_inference_for_single_image(detection_model, image_np)
# Visualization of the results of a detection.
# y x y x vis_util.visualize_boxes_and_labels_on_image_array( image_np,
output_dict['detection_boxes'], output_dict['detection_classes'], output_dict['detection_scores'], category_index,
instance_masks=output_dict.get('detection_masks_reframed', None), use_normalized_coordinates=True,
line_thickness=8) array = []
13
for i in range(len(output_dict['detection_classes'])):
if output_dict['detection_classes'][i]==3:
val = "xy" #The data to post it on thingspeak
url = "https://api.thingspeak.com/update?api_key= 19D0QBZR9WPDPRE4&fiel d1="+str(val)
response = urllib.request.urlopen(url)
print("Response after posting ",response,"\n") break
else:
val = "xn"
url = "https://api.thingspeak.com/update?api_key= 19D0QBZR9WPDPRE4&fiel d1="+str(val)
response = urllib.request.urlopen(url) print("Response after posting ",response,"\n")
display(Image.fromarray(image_np))
